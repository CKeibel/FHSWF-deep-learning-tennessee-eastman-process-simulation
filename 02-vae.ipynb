{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8875558-e752-48e1-ac01-84b17dba242f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pyreadr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0347738-3a4d-4d27-a4c3-dbded07c1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for path in glob.glob(\"data/*.RData\"):\n",
    "    _df = pyreadr.read_r(path)\n",
    "    k = list(_df.keys())[0]\n",
    "    _df =  _df[k]\n",
    "    df = pd.concat([df, _df])\n",
    "\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0acaca-9f75-432d-96e1-be13f1ae8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "df[\"faultNumber\"] = df[\"faultNumber\"].astype(int)\n",
    "df = df.drop([\"simulationRun\", \"sample\", \"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a8a8e-c6be-4163-ab47-2501f81d464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 3, 9 and 15\n",
    "mask = ~df[\"faultNumber\"].isin([3, 9, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2db25-f3c7-4931-b47a-1ad7d46c3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[mask]\n",
    "df[\"faultNumber\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b095e-2205-49bc-a222-7206b53af6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.loc[:, df.columns != \"faultNumber\"].values\n",
    "# labels\n",
    "y = df[\"faultNumber\"].values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c1a15-939e-4fb9-9a7f-d51afd8f480c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns[df.columns != \"faultNumber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d10c15-d0ff-4db2-b32a-eb6351867700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a513bc-c5dd-4666-bc92-c701ed3a0d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled_X, columns=df.columns[df.columns != \"faultNumber\"])\n",
    "scaled_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69feaf6-a9c6-4569-ab79-36993174bb63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec06a15-0cbc-4501-93ec-b3868b473434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(X, y, lookback=5):\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    with tqdm(total=len(X)-lookback-1) as pbar:\n",
    "        for i in range(len(X)-lookback-1):\n",
    "            _x = X[i:i+lookback, :]\n",
    "            _y = y[i+lookback+1]\n",
    "            x_out.append(_x)\n",
    "            y_out.append(_y)\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(\"Preparing numpy return. This could take some seconds.\")\n",
    "    return np.array(x_out), np.array(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817c47e-769b-4f91-a525-12a81b22b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x, _y = create_samples(scaled_df.values, y)\n",
    "_x.shape, _y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4a550-912a-4a75-8a0c-1af5cb319cfe",
   "metadata": {},
   "source": [
    "### Scaler\n",
    "The recommended way (see 'Elements of Statistical Learning', chapter 'The Wrong and Right Way to Do Cross-validation') is to calculate the **mean** and the **standard deviation** of the values in the **training set** and then **apply them for standardizing both the training and testing sets**.\n",
    "\n",
    "The idea behind this is to preven**t data leaka**ge from the testing to the training set because the aim of model validation is to subject the testing data to the same conditions as the data used for the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a3aac-3b5f-45ca-a977-1bc9a1d58d74",
   "metadata": {},
   "source": [
    "[Link](https://datascience.stackexchange.com/questions/63717/how-to-use-standardization-standardscaler-for-train-and-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce063d4-f4c4-4606-a219-2aef1e8640b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(_x, _y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a2dc0-81e6-4f48-9f91-3a9daaa65341",
   "metadata": {},
   "source": [
    "# LSTM VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7d54e-2937-4659-9c1a-902976744fc9",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9a3254-b672-4554-beab-31a7690adca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        output, (hidden_state, cell_state) = self.lstm(X)\n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9055cb-99a1-428f-a674-86419529e039",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa8e0e8-7ab0-47b2-91d3-666d001dd4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        # reconstruction\n",
    "        self.linear_recon = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        output, (hidden_state, cell_state) = self.lstm(X)\n",
    "        return self.linear_recon(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c87b16-432a-42a7-9af3-379924f0b369",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a3f5ea-3585-4f07-819f-98bbfdfd9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, num_layers, device):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.latent_size = latent_size\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            input_size=latent_size, # compressed vector size\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=input_size, # reconstruction of features at timestep\n",
    "            num_layers=num_layers\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.mean_linear = nn.Linear((self.hidden_size*self.num_layers), self.latent_size).to(self.device)\n",
    "        self.logvar_linear = nn.Linear((self.hidden_size*self.num_layers), self.latent_size).to(self.device)\n",
    "        #self.compressed_linear = nn.Linear(self.latent_size, self.hidden_size).to(self.device)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        # Gaussian (normal)\n",
    "        noise = torch.randn_like(std, device=self.device)\n",
    "        return mu + (noise * std)\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size, seq_len, features_dim = X.shape\n",
    "\n",
    "        # encode\n",
    "        # tensor of shape: 1*num_layers, batch_size, hidden_size\n",
    "        enc_hidden = self.encoder(X)\n",
    "        enc_hidden = enc_hidden.transpose(0, 1).contiguous().view(batch_size, -1) # (batch_size, hidden_size*num_layers)\n",
    "\n",
    "        # extract latent variable z (hidden to latent)\n",
    "        _mean = self.mean_linear(enc_hidden)\n",
    "        _logvar = self.logvar_linear(enc_hidden)\n",
    "        _z = self.reparametrize(_mean, _logvar) # Shape: batch_size, latent_size\n",
    "        _z = _z.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "\n",
    "        # hidden state\n",
    "        #_h = self.compressed_linear(_z) # batch_size, hidden_size\n",
    "        #_h = _h.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "\n",
    "        pred = self.decoder(_z)\n",
    "\n",
    "        return pred, _mean, _logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "423bc8ef-0dd2-425f-bd40-962712437a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(pred, label, _mean, _logvar):\n",
    "    #reconstruction_loss = nn.BCELoss(pred, label)\n",
    "    reconstruction_loss = F.mse_loss(pred, label)\n",
    "    kld_loss = torch.mean(\n",
    "            -0.5 * torch.sum(1 + _logvar - _mean**2 - _logvar.exp(), dim=1), dim=0\n",
    "        )\n",
    "    loss = reconstruction_loss + kld_loss #*kld_weight\n",
    "    return loss, reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1cb3932-605a-4cfe-bfee-bb72d10a1a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cb6dd49-1a2d-4a8f-864b-88e3ff32b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEP(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(TEP, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _x = self.x[idx]\n",
    "        _y = self.y[idx]\n",
    "        return _x, _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea0cdb39-8e2d-4721-8883-3b2413c30046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TEP(X_train, y_train)\n",
    "trainloader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec332b65-19b3-48a6-96c3-c0276605dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x, samle_y = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39139ae4-6b18-4166-ba47-eab813942402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 52])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78adf156-ec52-451b-9d84-680ac5d77605",
   "metadata": {},
   "source": [
    "## Overfitting on one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50175ed1-cfb3-4c95-a0ab-0af639faac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(879209.2500, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "\n",
    "sample_x = sample_x.to(torch.float32).to(device)\n",
    "\n",
    "learning_rate = 0.002\n",
    "\n",
    "model = VAE(input_size=52, hidden_size=128, latent_size=16, num_layers=12, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for i in range(num_epochs):\n",
    "    pred, _mean, _logvar = model(sample_x)\n",
    "    loss, reconstruction_loss = vae_loss(pred, sample_x, _mean, _logvar)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #print(f\"Reconstruction Loss: {reconstruction_loss}\")\n",
    "\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "745a90df-f5ef-4608-a0d5-dceb44db44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7958it [02:17, 58.03it/s, loss=9.9e+5] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m loss, reconstruction_loss \u001b[38;5;241m=\u001b[39m vae_loss(pred, x, _mean, _logvar)\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m _r \u001b[38;5;241m=\u001b[39m reconstruction_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\Documents\\lernen\\modul_deep_learning\\.tep-deep-learning\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\lernen\\modul_deep_learning\\.tep-deep-learning\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# trainloader\n",
    "train_data = TEP(X_train, y_train)\n",
    "trainloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "\n",
    "# model\n",
    "learning_rate = 0.0002\n",
    "model = VAE(input_size=52, hidden_size=128, latent_size=32, num_layers=8, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for i in range(num_epochs):\n",
    "    r_losses = []\n",
    "    loop = tqdm(enumerate(trainloader))\n",
    "    for _, (x, y) in loop:\n",
    "        x = x.to(torch.float32).to(device)\n",
    "        pred, _mean, _logvar = model(x)\n",
    "        loss, reconstruction_loss = vae_loss(pred, x, _mean, _logvar)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _r = reconstruction_loss.detach().item()\n",
    "        r_losses.append(_r)\n",
    "\n",
    "        loop.set_postfix(loss=_r)\n",
    "\n",
    "    print(f\"Reconstruction Loss: {np.mean(r_losses)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
